{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Header\n",
        "\n",
        "### Overview\n",
        "\n",
        "Breast cancer ranks first for incidence in females in 159 countries, and it alone accounted for approximately 30% of new female cancers in U.S. in 2020. The World Health Organization and American Cancer Association recommend organized and population-wide breast cancer screening to promote early detection and reduce mortality. Mammography has been the primary method for breast cancer screening, and the overall sensitivity of mammography for non-palpable cancers detection is about 85%. But the sensitivity of mammography detection of breast cancer for extremely dense breasts can be as low as 61%. In American women, it was estimated that 27.6 million women aged 40-74 years have heterogeneously or extremely dense breasts. Many studies has suggested that using breast ultrasound as supplemental screening with mammography or as primary imaging could significantly improve the sensitivity of cancer detection in women with dense breast.\n",
        "\n",
        " \n",
        "Recent research demonstrated that BUS with advanced machine learning approaches could achieve high sensitivity (94%-95%) and high specificity (89%-93%) for breast cancer detection. However, most approaches were trained and evaluated using small private datasets, and their performances degrade dramatically on datasets from different sources. This major drawback makes it difficult to deploy and adopt them in an open-world environment where we may encounter data with large variations.\n",
        "\n",
        "In this competition, you will develop approaches for breast cancer detection using a large B-model breast ultrasound dataset. More specifically, you will develop an approach that can automatically classify breast ultrasound images into the ‘benign’ and ‘malignant’ categories.\n",
        "\n",
        " \n",
        "\n",
        "### Dataset\n",
        "\n",
        "The dataset was collected from five countries and contains a total of 3,600 B-model breast ultrasound images, of which 1,837 contain benign tumors, and 1,763 are malignant tumors.\n",
        "\n",
        "Note the dataset can only be used for this competition, and sharing and usage for all other purposes are not allowed. Please sign the release agreement and send it to our TA. The dataset is available at http://bus.midalab.net/labeling Links to an external site.(Sign-up using your university email is required.)\n",
        "\n",
        "Release agreement\n",
        "\n",
        "### Evaluation\n",
        "\n",
        "To evaluate the performance of the approach, we use the following quantitative metrics: accuracy (Acc), sensitivity (Sens), and specificity (Spec). Acc values will be used as the primary ranking score, and Sens will be used as a secondary ranking score if a tie happens.\n",
        "\n",
        " \n",
        "\n",
        " Acc = (TP+ TN)/(TP+FP+TN+FN)\n",
        " Sens = TP/(TP+FN)\n",
        " Spec = ( TN)/(TN+FP)\n",
        "In Eqs.(1-3), TP is the number of true positives, TN is the number of true negatives, FP is the number of false positives, and FN is the number of false negatives.\n",
        "\n",
        " \n",
        "\n",
        "### Submission \n",
        "\n",
        "1. Please use this code Download this codeto prepare your data and save your results to 'test_pred.csv'. The csv file should have a 'name' and a 'pred' column. Here is a sample csv file test_pred.csv Download test_pred.csv.\n",
        "\n",
        "2. Submit the following files: 1) Python code, and 2) results (test_pred.csv) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning#fine_tuning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Colab\n",
        "\n",
        "- train.csv containing image name and target required\n",
        "- folders of test and training images required\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/SethCram/CS474-Deep-Learning/blob/main/HW4/HW4_CNN_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dQmHIT2Mtvz",
        "outputId": "09cc133b-10f4-444f-915d-a129dc8b00dd"
      },
      "outputs": [],
      "source": [
        "## Google Colab Cell\n",
        "\n",
        "#enable debugging\n",
        "!pip install -Uqq ipdb\n",
        "import ipdb\n",
        "%pdb on\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#seth act\n",
        "%cd /content/drive/MyDrive/School/Senior Year/CS 474-01 (Deep Learning)/\n",
        "#other act\n",
        "%cd /content/drive/MyDrive/DL-Proj4/\n",
        "\n",
        "#make sure GPU enabled\n",
        "!nvidia-smi\n",
        "\n",
        "#install proper TF version for convnext\n",
        "!pip install tensorflow==2.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2MIMrBnHj6D"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import convnext\n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "import keras \n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import applications\n",
        "from keras import losses\n",
        "from keras import callbacks\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2 as cv\n",
        "import csv\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "\n",
        "print(\"Modules imported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi3lNvXkHj6E",
        "outputId": "59eb91eb-b9e2-49d9-9a6d-e01836dffe24"
      },
      "outputs": [],
      "source": [
        "#LOAD CSV AND IMAGES (in proper resolution)\n",
        "\n",
        "df=pd.read_csv('train.csv', sep = ',')\n",
        "print(df)\n",
        "\n",
        "training_imgs_path = 'trainImgs/'\n",
        "test_imgs_path = 'testImgs/'\n",
        "\n",
        "targetWidth = 512 #500 #256 for imagenet\n",
        "targetHeight = 512 #500\n",
        "\n",
        "# store training and test imgs greyscaled \n",
        "x_train = np.array([\n",
        "            cv.resize( #resize to desired size\n",
        "                cv.imread(training_imgs_path + row[1] + \".png\"), \n",
        "                dsize=(targetWidth, targetHeight),\n",
        "            ) \n",
        "            for row in df.values\n",
        "    ])\n",
        "x_test = np.array([\n",
        "            cv.resize( #resize to desired size\n",
        "                cv.imread(test_imgs_path + str(i) + \".png\"),\n",
        "                dsize=(targetWidth, targetHeight),\n",
        "            )\n",
        "            for i in range(1248)\n",
        "    ])\n",
        "\n",
        "#store whether benign (0?) or malignant (1?)\n",
        "y_train = np.array([row[2] for row in df.values], dtype='float32')\n",
        "\n",
        "nImg = 4  \n",
        "for i in range(nImg*nImg):\n",
        "    plt.subplot(nImg, nImg, i+1)\n",
        "    plt.imshow(x_train[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ANOTHER WAY TO IMPORT DATA (possibly faster)\n",
        "\n",
        "# load all training images and labels\n",
        "train_img_folder = 'trainImgs'\n",
        "train = pd.read_csv('train.csv')\n",
        "print(train)\n",
        "\n",
        "targetWidth = 512 \n",
        "targetHeight = 512 \n",
        "input_size = 512\n",
        "\n",
        "trainImg_names = list(train['img name']) \n",
        "print('loading images ...')\n",
        "x_train = []\n",
        "for idx, name in enumerate(trainImg_names):\n",
        "    img = image.load_img(os.path.join(train_img_folder, name +'.png'), target_size = (input_size, input_size)) #color_mode = \"grayscale\",\n",
        "    img = image.img_to_array(img)\n",
        "    x_train.append(img)\n",
        "    #print(idx, name)\n",
        "x_train = np.array(x_train).astype(np.float32)\n",
        "y_train = np.array(train['tumor types'])\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train_onehot = tf.keras.utils.to_categorical(y_train)\n",
        "#print(y_train_onehot.shape)\n",
        "\n",
        "print('loading finished ...')\n",
        "#print(x_train.shape, y_train_onehot)\n",
        "\n",
        "nImg = 4  \n",
        "for i in range(nImg*nImg):\n",
        "    plt.subplot(nImg, nImg, i+1)\n",
        "    plt.imshow(x_train[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer Learning\n",
        "## Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comon Model Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_layer = layers.Input(shape=(targetWidth, targetHeight, 3))\n",
        "\n",
        "#data augmentation\n",
        "flip_layer = layers.RandomFlip()\n",
        "rot_layer = layers.RandomRotation( #seems to throw off models and slow down training\n",
        "        0.2,\n",
        "        fill_mode=\"constant\",\n",
        "        fill_value=0,\n",
        "    )\n",
        "translation_layer = layers.RandomTranslation(\n",
        "    height_factor=(-0.2, 0.2),\n",
        "    width_factor=(-0.2, 0.2),\n",
        "    fill_mode=\"constant\",\n",
        "    fill_value=0,\n",
        ")\n",
        "\n",
        "output_layer = layers.Dense(\n",
        "    units=1,\n",
        "    activation=keras.activations.sigmoid \n",
        ")\n",
        "\n",
        "nImg = 4  \n",
        "for i in range(nImg*nImg):\n",
        "    plt.subplot(nImg, nImg, i+1)\n",
        "    \n",
        "    aug_image = flip_layer(x_train[i])\n",
        "    aug_image = translation_layer(aug_image)\n",
        "    aug_image = rot_layer(aug_image)\n",
        "    \n",
        "    plt.imshow(aug_image.numpy().astype(\"uint8\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Common Model Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = flip_layer(input_layer)\n",
        "x = rot_layer(x)\n",
        "x = translation_layer(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VGG Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## VGG\n",
        "\n",
        "filename = \"vgg16_firstpass_retry_model\"\n",
        "\n",
        "#avg = 530\n",
        "#avg_training_width = sum( image.shape[0] for image in x_train ) / x_train.shape[0]\n",
        "#avg_training_height = sum( image.shape[1] for image in x_train ) / x_train.shape[0]\n",
        "#avg_test_width = sum( image.shape[0] for image in x_test ) / x_test.shape[0]\n",
        "#avg_test_height = sum( image.shape[1] for image in x_train ) / x_train.shape[0]\n",
        "\n",
        "# layer construction\n",
        "preprocc_input = applications.vgg16.preprocess_input\n",
        "base_model = applications.VGG16(\n",
        "    input_shape=(targetWidth, targetHeight, 3),\n",
        "    include_top=False,\n",
        ")\n",
        "flatten_layer = layers.Flatten()\n",
        "fc_layer = layers.Dense(512, activation='relu')\n",
        "# Add a dropout rate of 0.5\n",
        "dropout_layer = layers.Dropout(0.5)\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "#layer connecting\n",
        "x = preprocc_input(x) #training should be true here?\n",
        "x = base_model(x, training=False)\n",
        "x = flatten_layer(x)\n",
        "x = fc_layer(x)\n",
        "x = dropout_layer(x)\n",
        "predictions = output_layer(x)\n",
        "model = keras.Model(input_layer, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### InceptionV3 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"inceptronv3_firstpass_retry_model\"\n",
        "\n",
        "# layer construction\n",
        "preprocc_input = applications.inception_v3.preprocess_input\n",
        "\n",
        "base_model = applications.InceptionV3(\n",
        "    input_shape=(targetWidth, targetHeight, 3),\n",
        "    include_top=False,\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "global_avg_pool_layer = layers.GlobalAveragePooling2D()\n",
        "fc_layer = layers.Dense(1024, activation='relu')\n",
        "dropout_layer = layers.Dropout(0.2)\n",
        "\n",
        "#layer connecting\n",
        "x = preprocc_input(x) #training should be true here?\n",
        "x = base_model(x, training=False)\n",
        "x = global_avg_pool_layer(x)\n",
        "x = fc_layer(x)\n",
        "x = dropout_layer(x)\n",
        "predictions = output_layer(x)\n",
        "model = keras.Model(input_layer, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Efficient Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"EffNetB2_firstpass_model\"\n",
        "\n",
        "# layer construction\n",
        "preprocc_input = applications.efficientnet.preprocess_input\n",
        "base_model = applications.EfficientNetB2(\n",
        "    input_shape=(targetWidth, targetHeight, 3),\n",
        "    include_top=False,\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "fc_layer = layers.Dense(512, activation='relu')\n",
        "dropout_layer = layers.Dropout(0.3) \n",
        "\n",
        "#layer connecting\n",
        "x = preprocc_input(x) #training should be true here?\n",
        "x = base_model(x, training=False)\n",
        "x = flatten_layer(x)\n",
        "x = fc_layer(x)\n",
        "x = dropout_layer(x)\n",
        "predictions = output_layer(x)\n",
        "model = keras.Model(input_layer, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ConvNext Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"ConvNextTiny_finetune_firstpass_model\"\n",
        "\n",
        "# layer construction\n",
        "base_model = convnext.ConvNeXtTiny( #preproccing included\n",
        "    input_shape=(targetWidth, targetHeight, 3),\n",
        "    include_top=False,\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "#fc_layer = layers.Dense(216, activation='relu')\n",
        "#dropout_layer = layers.Dropout(0.3) \n",
        "\n",
        "#layer connecting\n",
        "x = base_model(x, training=False)\n",
        "x = flatten_layer(x)\n",
        "#x = fc_layer(x)\n",
        "#x = dropout_layer(x)\n",
        "predictions = output_layer(x)\n",
        "model = keras.Model(input_layer, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MobileNet V2 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"mobilenetv2_firstpass_finetuned3_model\"\n",
        "\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(targetWidth, targetHeight, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "base_model.trainable = False\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "\n",
        "#layer connecting\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(input_layer, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HuggingFace Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## UNTRAINABLE (doesn't use images)\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "\n",
        "filename = \"ENM/sciBERT-case-finetuned-breastcancer\"\n",
        "num_classes = 1\n",
        "batch_size = 32\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(filename)\n",
        "\n",
        "model = TFAutoModel.from_pretrained(filename, from_pt=True, num_labels=num_classes)\n",
        "#model.trainable = True\n",
        "\n",
        "model.summary(expand_nested=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Compilation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_learning_rate = 0.0001\n",
        "num_epochs = 10\n",
        "\n",
        "num_train_steps = len(x_train) * num_epochs\n",
        "\n",
        "lr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "        initial_learning_rate=base_learning_rate, end_learning_rate=0.0,\n",
        "        decay_steps=num_train_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=optimizers.Adam(), #learning_rate=lr_scheduler\n",
        "    loss=losses.BinaryCrossentropy(), #from_logits=True\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=optimizers.RMSprop(), #optimizers.rmsprop(lr=0.0001, decay=1e-6) #sometimes decay not included?\n",
        "    loss=losses.BinaryCrossentropy(), #from_logits=True\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#need to recompile model\n",
        "model.compile(\n",
        "    optimizer=optimizers.SGD(learning_rate=base_learning_rate, momentum=0.9), \n",
        "    loss=losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Post Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary(expand_nested=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Restoration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Restore Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## RESTORE THE MODEL\n",
        "\n",
        "filename = \"ConvNextTiny_firstpass_model\"\n",
        "\n",
        "model = keras.models.load_model(\"saved_models/\" + filename)\n",
        "\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "\n",
        "filename = \"ConvNextTiny_firstpass2_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Restore Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"inceptronv3_dropout3_finetuned_model\"\n",
        "\n",
        "model = keras.models.load_model(\"checkpoints/\" + filename)\n",
        "\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "\n",
        "filename = \"inceptronv3_dropout3_finetuned2.1_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fine Tuning\n",
        "\n",
        "shouldn't be finetuning if additional dense layer before output layer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model_index = 5\n",
        "\n",
        "#enable base model training\n",
        "model.layers[base_model_index ].trainable = True\n",
        "\n",
        "#disable all base model layers\n",
        "for base_model_layer in model.layers[base_model_index ].layers:\n",
        "    base_model_layer.trainable = False\n",
        "\n",
        "#make some conv2D layers trainable\n",
        "model.layers[base_model_index ].layers[299].trainable = True\n",
        "\n",
        "model.layers[base_model_index ].layers[294].trainable = True\n",
        "\n",
        "model.layers[base_model_index].layers[292].trainable = True\n",
        "model.layers[base_model_index].layers[291].trainable = True\n",
        "model.layers[base_model_index].layers[290].trainable = True\n",
        "model.layers[base_model_index].layers[289].trainable = True\n",
        "\n",
        "model.layers[base_model_index].layers[284].trainable = True\n",
        "model.layers[base_model_index].layers[283].trainable = True\n",
        "\n",
        "\n",
        "model.summary(expand_nested=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.layers[5].trainable = True\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 50\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in model.layers[5].layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "  \n",
        "model.summary(expand_nested=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#shuffle data everytime train\n",
        "x_train, y_train = shuffle(x_train, y_train)\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "early_stopping_callback = callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    min_delta=0.001,\n",
        "    patience=4,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "logger_callback = callbacks.CSVLogger(\n",
        "    filename=\"model_logs/\" + filename + '.csv',\n",
        "    separator=',',\n",
        "    append=True #don't overwrite if file exists already\n",
        ")\n",
        "\n",
        "#for periodically saving best model\n",
        "checkpoint_path = 'checkpoints/' + filename\n",
        "checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='tb_logs',\n",
        "    histogram_freq=2,\n",
        "    write_graph=True,\n",
        "    write_images=False,\n",
        "    write_steps_per_second=False,\n",
        "    update_freq='epoch',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#if retrain same model again:\n",
        "# filename = \"inceptronv3_firstpass_retry_finetuned2_model\"\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, \n",
        "    y_train, \n",
        "    epochs=num_epochs, \n",
        "    batch_size=batch_size,  #32 works well\n",
        "    validation_split=0.2, \n",
        "    validation_batch_size=batch_size,\n",
        "    shuffle=True, #shuffles data after every epoch to reduce overfitting\n",
        "    callbacks=[logger_callback, tb_callback, checkpoint_callback, early_stopping_callback], \n",
        "    workers=4,\n",
        "    use_multiprocessing = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#history of training and validation accuracy (only works if model trained and not preloaded)\n",
        "plt.plot(history.history['accuracy'], label='training acc')\n",
        "plt.plot(history.history['val_accuracy'], label='validation acc')\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## SAVE THE MODEL\n",
        "model.save(\"saved_models/\" + filename)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation\n",
        "## Model Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### New Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HdsbyQRHj6H"
      },
      "outputs": [],
      "source": [
        "## Model Prediction\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#test prediction storage\n",
        "y_test_pred = model.predict(\n",
        "        x_test, \n",
        "        batch_size=batch_size,\n",
        "        workers=4,\n",
        "        use_multiprocessing = True,\n",
        "    ).flatten()\n",
        "\n",
        "#round probabilities to 0 or 1\n",
        "y_test_pred = np.round(y_test_pred)\n",
        "\n",
        "\n",
        "with open('predictions/' + 'HW4_predictions_SethCram' + '_' + filename + '.csv', 'w') as file:\n",
        "    writer = csv.writer(file, lineterminator='\\n')\n",
        "    \n",
        "    for i in range(1248):\n",
        "        if i == 0:\n",
        "            writeList = [\"\", \"name\", \"pred\"]\n",
        "        else:\n",
        "            writeList = [i, \"testImgs\\\\\" + str(i-1) + \".png\", y_test_pred[i-1]]\n",
        "        \n",
        "        writer.writerow(writeList)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Translate Old Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = 'HW4_predictions_SethCram_ConvNextTiny_firstpass_model73.8%.csv'\n",
        "\n",
        "#for translating old preds to new format (requires manual insertion of 1st row)\n",
        "df=pd.read_csv('predictions/' + filename, sep = ',')\n",
        "print(df)\n",
        "\n",
        "with open('predictions/' + filename, 'w') as file:\n",
        "    writer = csv.writer(file, lineterminator='\\n')\n",
        "    \n",
        "    for i in range(1248):\n",
        "        if i == 0:\n",
        "            writeList = [\"\", \"name\", \"pred\"]\n",
        "        else:\n",
        "            #translate old pred into new format\n",
        "            writeList = [i, \"testImgs\\\\\" + df.values[i-1][0], df.values[i-1][1]]\n",
        "        \n",
        "        writer.writerow(writeList)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#train accuracy\n",
        "y_train_pred = model.predict(\n",
        "        x_train, \n",
        "        batch_size=batch_size,\n",
        "        #workers=4,\n",
        "        #use_multiprocessing = True,\n",
        "    ).flatten()\n",
        "\n",
        "#round probabilities to 0 or 1\n",
        "y_train_pred = np.round(y_train_pred)\n",
        "\n",
        "train_acc = np.sum(y_train.flatten() == y_train_pred) / y_train.shape[0]\n",
        "\n",
        "print(f'train accuracy: {train_acc * 100}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss0, accuracy0 = model.evaluate(x_train, y_train, batch_size=batch_size,)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('JupyterNotebook': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7e1b2f627b942c46ec4bf47ff4ea2a9cdb5031d2bd74349327a6cc0e56088180"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
