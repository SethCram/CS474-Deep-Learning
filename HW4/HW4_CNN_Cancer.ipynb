{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SethCram/CS474-Deep-Learning/blob/main/HW4/HW4_CNN_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2MIMrBnHj6D"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras \n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import applications\n",
        "from keras import losses\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2 as cv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dQmHIT2Mtvz",
        "outputId": "09cc133b-10f4-444f-915d-a129dc8b00dd"
      },
      "outputs": [],
      "source": [
        "## Google Colab Cell\n",
        "\n",
        "#enable debugging\n",
        "!pip install -Uqq ipdb\n",
        "import ipdb\n",
        "%pdb on\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/School/Senior Year/CS 474-01 (Deep Learning)/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Import\n",
        "## LOAD CSV AND IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi3lNvXkHj6E",
        "outputId": "59eb91eb-b9e2-49d9-9a6d-e01836dffe24"
      },
      "outputs": [],
      "source": [
        "#LOAD CSV AND IMAGES\n",
        "\n",
        "df=pd.read_csv('https://raw.githubusercontent.com/SethCram/CS474-Deep-Learning/main/HW4/train.csv', sep = ',')\n",
        "print(df)\n",
        "\n",
        "training_imgs_path = 'trainImgs/'\n",
        "test_imgs_path = 'testImgs/'\n",
        "\n",
        "# store training and test imgs greyscaled \n",
        "x_train_diff_reses = np.array([\n",
        "        cv.imread(training_imgs_path + row[1] + \".png\", 0).astype('float32') for row in df.values], \n",
        "        dtype='object'\n",
        "    )\n",
        "x_test_diff_reses = np.array([\n",
        "        cv.imread(test_imgs_path + str(i) + \".png\", 0).astype('float32') \n",
        "        for i in range(1248)], \n",
        "        dtype='object'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Images\n",
        "ONLY RUNNABLE A SINGLE TIME PER SESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILcFYq4tHj6F"
      },
      "outputs": [],
      "source": [
        "#ONLY RUNNABLE A SINGLE TIME PER SESSION\n",
        "def load_imgs(x_train_size, x_test_size, max_width, max_height, show_sample = True, batch_size=100):\n",
        "    \n",
        "    ## Data Preprocessing\n",
        "    \n",
        "    #need to do some sort of zero/same padding to get same image sizes\n",
        "    # unless using fully convolutional NN bc can take inputs of different sizes\n",
        "    # or if use a spatial pyramid pooling (SPP) layer before dense layers\n",
        "    \n",
        "    #Could possibly create more training data thru upscaling/downscaling\n",
        "    # would better recognise diff scaled data\n",
        "    # or get same size of inputs too\n",
        "    \n",
        "    x_train = np.empty((x_train_size, max_width, max_height), dtype='float32')\n",
        "    x_test = np.empty((x_test_size, max_width, max_height), dtype='float32')\n",
        "    \n",
        "    for i, image in enumerate(x_train_diff_reses):\n",
        "        #x_train_diff_reses[i] = pad_image(\n",
        "        #    image, \n",
        "        #    biggest_training_width, \n",
        "        #    biggest_training_height\n",
        "        #)\n",
        "        \n",
        "        x_train[i] = cv.copyMakeBorder(\n",
        "            image, \n",
        "            0, \n",
        "            max_height-image.shape[0], \n",
        "            0, \n",
        "            max_width-image.shape[1], \n",
        "            cv.BORDER_CONSTANT\n",
        "        )/255.0 #normalize\n",
        "\n",
        "    #x_train = np.expand_dims(x_train, -1)\n",
        "\n",
        "    for i, image in enumerate(x_test_diff_reses):\n",
        "        #x_train_diff_reses[i] = pad_image(\n",
        "        #    image, \n",
        "        #    biggest_training_width, \n",
        "        #    biggest_training_height\n",
        "        #)\n",
        "        \n",
        "        x_test[i] = cv.copyMakeBorder(\n",
        "            image, \n",
        "            0, \n",
        "            max_height-image.shape[0], \n",
        "            0, \n",
        "            max_width-image.shape[1], \n",
        "            cv.BORDER_CONSTANT\n",
        "        )/255.0 #normalize\n",
        "\n",
        "    #x_test = np.expand_dims(x_test, -1)\n",
        "    \n",
        "    #assert biggest_test_width == min( image.shape[0] for image in x_test_diff_reses )\n",
        "    #assert biggest_test_height == min( image.shape[1] for image in x_test_diff_reses )\n",
        "    \n",
        "    #assert biggest_training_width == min( image.shape[0] for image in x_train_diff_reses )\n",
        "    #assert biggest_training_height == min( image.shape[1] for image in x_train_diff_reses )\n",
        "\n",
        "    #m = len(x_train_diff_reses)\n",
        "    #for b in range(int(m/batch_size)):\n",
        "    #    b_start= b*batch_size\n",
        "    #    b_end = min((b+1)*batch_size, m)\n",
        "    #    \n",
        "    #    x_batch = x_train_diff_reses[b_start:b_end]\n",
        "    #    x_train[b_start:b_end] = construct_image_batch(x_batch)\n",
        "    \n",
        "    #store whether benign (0?) or malignant (1?)\n",
        "    y_train = np.array([row[2] for row in df.values], dtype='float32')\n",
        "    y_test = np.zeros(x_test.shape[0], dtype='float32') #no labels on test data??\n",
        "    \n",
        "    #show first 100 images\n",
        "    if show_sample == True:\n",
        "        nImg = 4\n",
        "        for i in range(nImg*nImg):\n",
        "            plt.subplot(nImg, nImg, i+1)\n",
        "            plt.imshow(x_train[i], cmap = 'Greys_r')\n",
        "        plt.show()\n",
        "        \n",
        "    #x_train = np.reshape(x_train, [x_train.shape[0], x_train.shape[1] * x_train.shape[2]]) #adds 2nd dim of 1\n",
        "    #x_test = np.reshape(x_test, [x_test.shape[0], x_test.shape[1] * x_test.shape[2]]) #adds 2nd dim of 1\n",
        "        \n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "#Get training and test max resolutions\n",
        "biggest_training_width = max( image.shape[0] for image in x_train_diff_reses )\n",
        "biggest_training_height = max( image.shape[1] for image in x_train_diff_reses )\n",
        "\n",
        "biggest_test_width = max( image.shape[0] for image in x_test_diff_reses )\n",
        "biggest_test_height = max( image.shape[1] for image in x_test_diff_reses )\n",
        "\n",
        "#get max width and height of any input image\n",
        "max_width = max( [biggest_test_width, biggest_training_width] )\n",
        "max_height = max( [biggest_test_height, biggest_training_height] )\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_imgs(len(x_train_diff_reses), len(x_test_diff_reses), max_width, max_height,)\n",
        "\n",
        "print('Data shape:', 'x_train:', x_train.shape, 'x_test:', x_test.shape)\n",
        "print('Data shape:', 'y_train:', y_train.shape, 'y_test:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN Model\n",
        "## Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#CNN MODEL\n",
        "\n",
        "model_CNN = keras.Sequential()\n",
        "\n",
        "input_layer = layers.Input(\n",
        "    shape=(max_width, max_height, 1),\n",
        ")\n",
        "model_CNN.add(input_layer)\n",
        "\n",
        "conv_1_layer = layers.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=3,\n",
        "        activation='relu'\n",
        "    )\n",
        "model_CNN.add(conv_1_layer)\n",
        "\n",
        "conv_2_layer = layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=3,\n",
        "        activation='relu'\n",
        "    )\n",
        "model_CNN.add(conv_2_layer)\n",
        "\n",
        "conv_3_layer = layers.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=3,\n",
        "        activation='relu'\n",
        "    )\n",
        "model_CNN.add(conv_3_layer)\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "model_CNN.add(flatten_layer)\n",
        "\n",
        "output_layer = layers.Dense(1, activation='softmax')\n",
        "model_CNN.add(output_layer)\n",
        "\n",
        "model_CNN.compile(\n",
        "    optimizer='adam', #to deal with noise\n",
        "    loss=losses.BinaryCrossentropy(), #or just categorical_crossentropy?\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_CNN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNN Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TRAIN CNN MODEL\n",
        "\n",
        "batch_size = 5 #1 epoch ETA = 2:15:00, 2 epoch ETA = 1:53:00, 3, 4, 5 epoch ETA = 1:30:00 epoch works; 6, 10, 64 doesn't work bc OOM\n",
        "\n",
        "#for debugging, could train with subset of overall data\n",
        "# could do 100 train images and less test images\n",
        "# resulted in epoch run time of 3 minutes = 100, 80\n",
        "# fastest of 20s per epoch = 10, 10\n",
        "#x_train = x_train[0:10]\n",
        "#y_train = y_train[0:10]\n",
        "#x_test = x_test[0:10]\n",
        "#y_test = y_test[0:10]\n",
        "\n",
        "history_CNN = model_CNN.fit(\n",
        "    x_train, \n",
        "    y_train,\n",
        "    epochs=2, #5, \n",
        "    batch_size=batch_size,  \n",
        "    validation_split=0.2, \n",
        "    validation_batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save/Restore Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## SAVE THE MODEL\n",
        "\n",
        "model_CNN.save(\"saved_models/cnn_undertrained_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## RESTORE THE MODEL\n",
        "\n",
        "model_CNN = keras.models.load_model(\"saved_models/cnn_undertrained_model\")\n",
        "\n",
        "model_CNN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fully Conv NN (FCN)\n",
        "## Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5uxl6ePHj6G",
        "outputId": "4944fa13-c62c-4945-b6b5-d8e11eecf5de"
      },
      "outputs": [],
      "source": [
        "# FULLY CONVOLUTION NN (FCN)\n",
        "\n",
        "def construct_image_batch(image_group, BATCH_SIZE):\n",
        "    # get the max image shape\n",
        "    max_shape = tuple(max(image.shape[x] for image in image_group) for x in range(3))\n",
        "\n",
        "    # construct an image batch object\n",
        "    image_batch = np.zeros((BATCH_SIZE,) + max_shape, dtype='float32')\n",
        "\n",
        "    # copy all images to the upper left part of the image batch object\n",
        "    for image_index, image in enumerate(image_group):\n",
        "        image_batch[image_index, :image.shape[0], :image.shape[1], :image.shape[2]] = image\n",
        "\n",
        "    return image_batch\n",
        "\n",
        "classes = 2\n",
        "\n",
        "# Input layer\n",
        "input = layers.Input(shape=(231, 231, 1)) #test with smallest input shape to determine # of conv blocks?\n",
        "\n",
        "# input convolution block\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, strides=1)(input)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "\n",
        "# middle convolution block\n",
        "#x = layers.Conv2D(filters=64, kernel_size=3, strides=1)(x)\n",
        "#x = layers.Dropout(0.2)(x)\n",
        "#x = layers.BatchNormalization()(x)\n",
        "#x = layers.Activation('relu')(x)\n",
        "\n",
        "# middle convolution block\n",
        "#x = layers.Conv2D(filters=32, kernel_size=3, strides=1)(x)\n",
        "#x = layers.Dropout(0.2)(x)\n",
        "#x = layers.BatchNormalization()(x)\n",
        "#x = layers.Activation('relu')(x)\n",
        "\n",
        "# final convolution block\n",
        "x = layers.Conv2D(filters=classes, kernel_size=1, strides=1)(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.GlobalMaxPooling2D()(x)\n",
        "predictions = layers.Activation('relu')(x)\n",
        "\n",
        "model = keras.Model(inputs=input, outputs=predictions)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO5uAwL4Hj6G",
        "outputId": "83dc57e0-a9af-4ec2-989c-03009f8ee725"
      },
      "outputs": [],
      "source": [
        "# TRAIN FCN\n",
        "\n",
        "def train(model, train_generator, val_generator, epochs = 50):\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "    checkpoint_path = './snapshots'\n",
        "    os.makedirs(checkpoint_path, exist_ok=True)\n",
        "    model_path = os.path.join(checkpoint_path, 'model_epoch_{epoch:02d}_loss_{loss:.2f}_acc_{acc:.2f}_val_loss_{val_loss:.2f}_val_acc_{val_acc:.2f}.h5')\n",
        "    \n",
        "    history = model.fit_generator(generator=train_generator,\n",
        "            steps_per_epoch=len(train_generator),\n",
        "            epochs=epochs,\n",
        "            callbacks=[keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)],\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=len(val_generator)\n",
        "        )\n",
        "\n",
        "    return history\n",
        "\n",
        "#train model\n",
        "history = model_fcn.fit(\n",
        "    x_train, #should be 2d inputs\n",
        "    y_train, #already onehot\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_split=0.2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7HdsbyQRHj6H"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model_CNN' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#test accuracy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_test_pred \u001b[39m=\u001b[39m model_CNN\u001b[39m.\u001b[39mpredict(x_test, batch_size\u001b[39m=\u001b[39mbatch_size)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m      4\u001b[0m test_acc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(y_test \u001b[39m==\u001b[39m y_test_pred) \u001b[39m/\u001b[39m y_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_acc \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model_CNN' is not defined"
          ]
        }
      ],
      "source": [
        "#test accuracy\n",
        "y_test_pred = model_CNN.predict(x_test, batch_size=batch_size).flatten()\n",
        "\n",
        "test_acc = np.sum(y_test == y_test_pred) / y_test.shape[0]\n",
        "\n",
        "print(f'test accuracy: {test_acc * 100}')\n",
        "\n",
        "#train accuracy\n",
        "y_train_pred = model_CNN.predict(x_train, batch_size=batch_size).flatten()\n",
        "\n",
        "train_acc = np.sum(y_train == y_train_pred) / y_train.shape[0]\n",
        "\n",
        "print(f'train accuracy: {train_acc * 100}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKaKEEa0Hj6H"
      },
      "outputs": [],
      "source": [
        "#history of training and validation accuracy (only works if model trained and not preloaded)\n",
        "plt.plot(history_CNN.history['accuracy'])\n",
        "plt.plot(history_CNN.history['val_accuracy'])\n",
        "plt.legend(['training acc', 'validation acc'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unused Cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2J8oG7QHj6H"
      },
      "outputs": [],
      "source": [
        "#get access to filters/kernels\n",
        "weights = convLayers[0].get_weights()[0][:, :, 0, :] #arr of a buncha nested lists, 0 bc only have 1 channel (28, 28, 1, 8)\n",
        "\n",
        "#can get access to other params this way \n",
        "\n",
        "for i in range(1, 8):\n",
        "    plt.subplot(2, 4, i)\n",
        "    plt.imshow(weights[:,:,i], cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "#how get access to feature maps?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# UNUSED\n",
        "\n",
        "#preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "## load the cancer dataset\n",
        "def construct_image_batch(image_group):\n",
        "    \n",
        "    # get the max image shape\n",
        "    max_shape = tuple(max(image.shape[x] for image in image_group) for x in range(2))\n",
        "\n",
        "    # construct an image batch object\n",
        "    image_batch = np.zeros((len(image_group),) + max_shape, dtype='float32')\n",
        "\n",
        "    # copy all images to the upper left part of the image batch object\n",
        "    for image_index, image in enumerate(image_group):\n",
        "        image_batch[image_index, :image.shape[0], :image.shape[1]] = image\n",
        "\n",
        "    return image_batch\n",
        "\n",
        "def pad_image(image, maxX, maxY):\n",
        "    #apply zero padding to smaller images\n",
        "    zero_image = np.zeros(\n",
        "        (maxX, maxY),\n",
        "         dtype='float32'\n",
        "    )\n",
        "    # copy image to the upper left part of zero image\n",
        "    zero_image[:image.shape[0], :image.shape[1]] = image\n",
        "    \n",
        "    return zero_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CDsQ12PHj6F",
        "outputId": "7197a498-b39f-4ea4-e7c9-d4e4a43bd8a2"
      },
      "outputs": [],
      "source": [
        "# UNUSED \n",
        "\n",
        "# expand dims for channels?\n",
        "\n",
        "#model = applications.resnet_v2.ResNet101V2(\n",
        "#    include_top=False,\n",
        "#    weights='imagenet',\n",
        "#    input_tensor=x_train,\n",
        "#    input_shape=x_train.shape,\n",
        "#    pooling=None,\n",
        "#    classes=1,\n",
        "#    classifier_activation='softmax'\n",
        "#)\n",
        "\n",
        "desiredLevels = 2\n",
        "\n",
        "def CreateConvLayer(convLayers, model, filters, kernel_size, activation = None, padding = \"valid\"):\n",
        "    conv = layers.Conv2D(\n",
        "        filters= filters, #num of filters for conv\n",
        "        kernel_size = kernel_size, \n",
        "        padding = padding,\n",
        "        activation = activation,\n",
        "        #input_shape = (28, 28, 1) #only 28 params \n",
        "    )\n",
        "    \n",
        "    convLayers.append(conv)\n",
        "    model.add(conv)\n",
        "    \n",
        "def CreateMaxPoolLayer(poolLayers, model, pool_size, strides):\n",
        "    pool = layers.MaxPooling2D(\n",
        "        pool_size = pool_size,\n",
        "        strides = strides,\n",
        "    )\n",
        "    \n",
        "    poolLayers.append(pool)\n",
        "    model.add(pool)\n",
        "    \n",
        "def CreateConvBlock(\n",
        "    model, convLayers, poolLayers, normLayers, activationLayers,\n",
        "    filters, kernel_size, activation,\n",
        "    pool_size, strides\n",
        "):\n",
        "    CreateConvLayer(convLayers, model, filters, kernel_size)\n",
        "    #CreateMaxPoolLayer(poolLayers, model, pool_size, strides)\n",
        "    \n",
        "    dropout = layers.Dropout(0.2)\n",
        "    model.add(dropout)\n",
        "    \n",
        "    norm = layers.BatchNormalization()\n",
        "    model.add(norm)\n",
        "    normLayers.append(norm)\n",
        "\n",
        "    activ = layers.Activation(activation)\n",
        "    model.add(activ)\n",
        "    activationLayers.append(activ)\n",
        "    \n",
        "# Create a fully conv NN\n",
        "model_fcn = keras.Sequential()\n",
        "\n",
        "convLayers = []\n",
        "poolLayers = []\n",
        "normLayers = []\n",
        "activationLayers = []\n",
        "\n",
        "# Input layer\n",
        "input = layers.Input(shape=(None, None, 1))\n",
        "model_fcn.add(input)\n",
        "\n",
        "CreateConvBlock(\n",
        "    model_fcn, convLayers, poolLayers, normLayers, activationLayers,\n",
        "    filters=8, kernel_size=3, activation='relu',\n",
        "    pool_size=2, strides=2\n",
        ")\n",
        "\n",
        "CreateConvBlock(\n",
        "    model_fcn, convLayers, poolLayers, normLayers, activationLayers,\n",
        "    filters=16, kernel_size=3, activation='softmax',\n",
        "    pool_size=2, strides=2\n",
        ")\n",
        "\n",
        "globMaxPool = layers.GlobalMaxPooling2D()\n",
        "model_fcn.add(globMaxPool)\n",
        "\n",
        "#model_fcn(inputs=x_train, outputs=y_train)\n",
        "\n",
        "#need normalization and output layers\n",
        "\n",
        "#specify optimization\n",
        "model_fcn.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_fcn.summary()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('JupyterNotebook': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7e1b2f627b942c46ec4bf47ff4ea2a9cdb5031d2bd74349327a6cc0e56088180"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
