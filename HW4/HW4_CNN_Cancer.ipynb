{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SethCram/CS474-Deep-Learning/blob/main/HW4/HW4_CNN_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J2MIMrBnHj6D"
      },
      "outputs": [],
      "source": [
        "import keras \n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import applications\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2 as cv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dQmHIT2Mtvz",
        "outputId": "09cc133b-10f4-444f-915d-a129dc8b00dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automatic pdb calling has been turned ON\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/School/Senior Year/CS 474-01 (Deep Learning)\n"
          ]
        }
      ],
      "source": [
        "## Google Colab Cell\n",
        "\n",
        "#enable debugging\n",
        "!pip install -Uqq ipdb\n",
        "import ipdb\n",
        "%pdb on\n",
        "\n",
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/School/Senior Year/CS 474-01 (Deep Learning)/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi3lNvXkHj6E",
        "outputId": "59eb91eb-b9e2-49d9-9a6d-e01836dffe24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0         img name  tumor types\n",
            "0              0           000137            1\n",
            "1              1         case0419            1\n",
            "2              2         case0024            0\n",
            "3              3     benign (397)            0\n",
            "4              4         case0287            0\n",
            "...          ...              ...          ...\n",
            "2379        2379  malignant (143)            1\n",
            "2380        2380         case0441            1\n",
            "2381        2381     benign (162)            0\n",
            "2382        2382           000064            0\n",
            "2383        2383           000022            0\n",
            "\n",
            "[2384 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#Load data\n",
        "df=pd.read_csv('https://raw.githubusercontent.com/SethCram/CS474-Deep-Learning/main/HW4/train.csv', sep = ',')\n",
        "print(df)\n",
        "\n",
        "training_imgs_path = 'trainImgs/'\n",
        "test_imgs_path = 'testImgs/'\n",
        "\n",
        "# store training and test imgs greyscaled \n",
        "x_train_diff_reses = np.array([\n",
        "        cv.imread(training_imgs_path + row[1] + \".png\", 0).astype('float32') for row in df.values], \n",
        "        dtype='object'\n",
        "    )\n",
        "x_test_diff_reses = np.array([\n",
        "        cv.imread(test_imgs_path + str(i) + \".png\", 0).astype('float32') \n",
        "        for i in range(1248)], \n",
        "        dtype='object'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ILcFYq4tHj6F"
      },
      "outputs": [
        {
          "ename": "UnboundLocalError",
          "evalue": "local variable 'x_test' referenced before assignment",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [3], line 121\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[39m#x_train = np.reshape(x_train, [x_train.shape[0], x_train.shape[1] * x_train.shape[2]]) #adds 2nd dim of 1\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39m#x_test = np.reshape(x_test, [x_test.shape[0], x_test.shape[1] * x_test.shape[2]]) #adds 2nd dim of 1\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m x_train, y_train, x_test, y_test\n\u001b[1;32m--> 121\u001b[0m x_train, y_train, x_test, y_test \u001b[39m=\u001b[39m load_imgs(x_train_diff_reses, x_test_diff_reses)\n\u001b[0;32m    123\u001b[0m \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mData shape:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx_train:\u001b[39m\u001b[39m'\u001b[39m, x_train\u001b[39m.\u001b[39mshape, \u001b[39m'\u001b[39m\u001b[39mx_test:\u001b[39m\u001b[39m'\u001b[39m, x_test\u001b[39m.\u001b[39mshape)\n",
            "Cell \u001b[1;32mIn [3], line 88\u001b[0m, in \u001b[0;36mload_imgs\u001b[1;34m(x_train_diff_reses, x_test_diff_reses, show_sample, batch_size)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mfor\u001b[39;00m i, image \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(x_test_diff_reses):\n\u001b[0;32m     73\u001b[0m     \u001b[39m#x_train_diff_reses[i] = pad_image(\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[39m#    image, \u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[39m#    biggest_training_width, \u001b[39;00m\n\u001b[0;32m     76\u001b[0m     \u001b[39m#    biggest_training_height\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[39m#)\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     x_test_diff_reses[i] \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mcopyMakeBorder(\n\u001b[0;32m     80\u001b[0m         image, \n\u001b[0;32m     81\u001b[0m         \u001b[39m0\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m         cv\u001b[39m.\u001b[39mBORDER_CONSTANT\n\u001b[0;32m     86\u001b[0m     )\n\u001b[1;32m---> 88\u001b[0m x_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(x_test), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[39massert\u001b[39;00m biggest_test_width \u001b[39m==\u001b[39m \u001b[39mmin\u001b[39m( image\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m x_test_diff_reses )\n\u001b[0;32m     91\u001b[0m \u001b[39massert\u001b[39;00m biggest_test_height \u001b[39m==\u001b[39m \u001b[39mmin\u001b[39m( image\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m x_test_diff_reses )\n",
            "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'x_test' referenced before assignment"
          ]
        }
      ],
      "source": [
        "#preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "## load the cancer dataset\n",
        "def construct_image_batch(image_group):\n",
        "    \n",
        "    # get the max image shape\n",
        "    max_shape = tuple(max(image.shape[x] for image in image_group) for x in range(2))\n",
        "\n",
        "    # construct an image batch object\n",
        "    image_batch = np.zeros((len(image_group),) + max_shape, dtype='float32')\n",
        "\n",
        "    # copy all images to the upper left part of the image batch object\n",
        "    for image_index, image in enumerate(image_group):\n",
        "        image_batch[image_index, :image.shape[0], :image.shape[1]] = image\n",
        "\n",
        "    return image_batch\n",
        "\n",
        "def pad_image(image, maxX, maxY):\n",
        "    #apply zero padding to smaller images\n",
        "    zero_image = np.zeros(\n",
        "        (maxX, maxY),\n",
        "         dtype='float32'\n",
        "    )\n",
        "    # copy image to the upper left part of zero image\n",
        "    zero_image[:image.shape[0], :image.shape[1]] = image\n",
        "    \n",
        "    return zero_image\n",
        "\n",
        "def load_imgs(x_train_diff_reses, x_test_diff_reses, show_sample = True, batch_size=100):\n",
        "    \n",
        "    ## Data Preprocessing\n",
        "    \n",
        "    #need to do some sort of zero/same padding to get same image sizes\n",
        "    # unless using fully convolutional NN bc can take inputs of different sizes\n",
        "    # or if use a spatial pyramid pooling (SPP) layer before dense layers\n",
        "    \n",
        "    #Could possibly create more training data thru upscaling/downscaling\n",
        "    # would better recognise diff scaled data\n",
        "    \n",
        "    #resolutions = np.array(resolutions).T\n",
        "\n",
        "    #Get training and test max resolutions\n",
        "    biggest_training_width = max( image.shape[0] for image in x_train_diff_reses )\n",
        "    biggest_training_height = max( image.shape[1] for image in x_train_diff_reses )\n",
        "\n",
        "    biggest_test_width = max( image.shape[0] for image in x_test_diff_reses )\n",
        "    biggest_test_height = max( image.shape[1] for image in x_test_diff_reses )\n",
        "    \n",
        "    for i, image in enumerate(x_train_diff_reses):\n",
        "        #x_train_diff_reses[i] = pad_image(\n",
        "        #    image, \n",
        "        #    biggest_training_width, \n",
        "        #    biggest_training_height\n",
        "        #)\n",
        "        \n",
        "        x_train_diff_reses[i] = cv.copyMakeBorder(\n",
        "            image, \n",
        "            0, \n",
        "            biggest_training_height-image.shape[0], \n",
        "            0, \n",
        "            biggest_training_width-image.shape[1], \n",
        "            cv.BORDER_CONSTANT\n",
        "        )\n",
        "        \n",
        "    assert biggest_training_width == min( image.shape[0] for image in x_train_diff_reses )\n",
        "    assert biggest_training_height == min( image.shape[1] for image in x_train_diff_reses )\n",
        "\n",
        "    x_train = np.array(list(x_train_diff_reses), dtype=\"float32\")\n",
        "\n",
        "    #x_train = x_train_diff_reses.reshape((len(x_train_diff_reses), x_train_diff_reses[0].shape[0], x_train_diff_reses[0].shape[1]) )#.astype('float32')\n",
        "\n",
        "    for i, image in enumerate(x_test_diff_reses):\n",
        "        #x_train_diff_reses[i] = pad_image(\n",
        "        #    image, \n",
        "        #    biggest_training_width, \n",
        "        #    biggest_training_height\n",
        "        #)\n",
        "        \n",
        "        x_test_diff_reses[i] = cv.copyMakeBorder(\n",
        "            image, \n",
        "            0, \n",
        "            biggest_test_height-image.shape[0], \n",
        "            0, \n",
        "            biggest_test_width-image.shape[1], \n",
        "            cv.BORDER_CONSTANT\n",
        "        )\n",
        "\n",
        "    x_test = np.array(list(x_test_diff_reses), dtype=\"float32\")\n",
        "    \n",
        "    assert biggest_test_width == min( image.shape[0] for image in x_test_diff_reses )\n",
        "    assert biggest_test_height == min( image.shape[1] for image in x_test_diff_reses )\n",
        "\n",
        "    #x_train = np.empty((len(x_train_diff_reses), biggest_training_width, biggest_training_height))\n",
        "    #x_test = np.empty((len(x_train_diff_reses), biggest_training_width, biggest_training_height))\n",
        "    \n",
        "    #m = len(x_train_diff_reses)\n",
        "    #for b in range(int(m/batch_size)):\n",
        "    #    b_start= b*batch_size\n",
        "    #    b_end = min((b+1)*batch_size, m)\n",
        "    #    \n",
        "    #    x_batch = x_train_diff_reses[b_start:b_end]\n",
        "    #    x_train[b_start:b_end] = construct_image_batch(x_batch)\n",
        "    \n",
        "    #store whether benign (0?) or malignant (1?)\n",
        "    y_train = np.array([row[2] for row in df.values], dtype=object)\n",
        "    y_test = 0 #no labels on test data??\n",
        "    \n",
        "    #show first 100 images\n",
        "    if show_sample == True:\n",
        "        nImg = 4\n",
        "        for i in range(nImg*nImg):\n",
        "            plt.subplot(nImg, nImg, i+1)\n",
        "            plt.imshow(x_train_diff_reses[i], cmap = 'Greys_r')\n",
        "        plt.show()\n",
        "        \n",
        "    #x_train = np.reshape(x_train, [x_train.shape[0], x_train.shape[1] * x_train.shape[2]]) #adds 2nd dim of 1\n",
        "    #x_test = np.reshape(x_test, [x_test.shape[0], x_test.shape[1] * x_test.shape[2]]) #adds 2nd dim of 1\n",
        "        \n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_imgs(x_train_diff_reses, x_test_diff_reses)\n",
        "\n",
        "pass\n",
        "\n",
        "print('Data shape:', 'x_train:', x_train.shape, 'x_test:', x_test.shape)\n",
        "print('Data shape:', 'y_train:', y_train.shape, 'y_test:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CDsQ12PHj6F",
        "outputId": "7197a498-b39f-4ea4-e7c9-d4e4a43bd8a2"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "`input_shape` must be a tuple of three integers.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# expand dims for channels?\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m applications\u001b[39m.\u001b[39mresnet_v2\u001b[39m.\u001b[39mResNet101V2(\n\u001b[0;32m      4\u001b[0m     include_top\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m     weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     input_tensor\u001b[39m=\u001b[39mx_train,\n\u001b[0;32m      7\u001b[0m     input_shape\u001b[39m=\u001b[39mx_train\u001b[39m.\u001b[39mshape,\n\u001b[0;32m      8\u001b[0m     pooling\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m     classes\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     10\u001b[0m     classifier_activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m desiredLevels \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mCreateConvLayer\u001b[39m(convLayers, model, filters, kernel_size, activation \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, padding \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\crazy\\source\\repos\\CS474-Deep-Learning\\JupyterNotebook\\lib\\site-packages\\keras\\applications\\resnet_v2.py:85\u001b[0m, in \u001b[0;36mResNet101V2\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m     82\u001b[0m     x \u001b[39m=\u001b[39m resnet\u001b[39m.\u001b[39mstack2(x, \u001b[39m256\u001b[39m, \u001b[39m23\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m resnet\u001b[39m.\u001b[39mstack2(x, \u001b[39m512\u001b[39m, \u001b[39m3\u001b[39m, stride1\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m \u001b[39mreturn\u001b[39;00m resnet\u001b[39m.\u001b[39;49mResNet(\n\u001b[0;32m     86\u001b[0m     stack_fn,\n\u001b[0;32m     87\u001b[0m     \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     88\u001b[0m     \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     89\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mresnet101v2\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     90\u001b[0m     include_top,\n\u001b[0;32m     91\u001b[0m     weights,\n\u001b[0;32m     92\u001b[0m     input_tensor,\n\u001b[0;32m     93\u001b[0m     input_shape,\n\u001b[0;32m     94\u001b[0m     pooling,\n\u001b[0;32m     95\u001b[0m     classes,\n\u001b[0;32m     96\u001b[0m     classifier_activation\u001b[39m=\u001b[39;49mclassifier_activation,\n\u001b[0;32m     97\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\crazy\\source\\repos\\CS474-Deep-Learning\\JupyterNotebook\\lib\\site-packages\\keras\\applications\\resnet.py:159\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIf using `weights` as `\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m` with `include_top`\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m as true, `classes` should be 1000\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m \u001b[39m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m input_shape \u001b[39m=\u001b[39m imagenet_utils\u001b[39m.\u001b[39;49mobtain_input_shape(\n\u001b[0;32m    160\u001b[0m     input_shape,\n\u001b[0;32m    161\u001b[0m     default_size\u001b[39m=\u001b[39;49m\u001b[39m224\u001b[39;49m,\n\u001b[0;32m    162\u001b[0m     min_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m    163\u001b[0m     data_format\u001b[39m=\u001b[39;49mbackend\u001b[39m.\u001b[39;49mimage_data_format(),\n\u001b[0;32m    164\u001b[0m     require_flatten\u001b[39m=\u001b[39;49minclude_top,\n\u001b[0;32m    165\u001b[0m     weights\u001b[39m=\u001b[39;49mweights,\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m input_tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     img_input \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minput_shape)\n",
            "File \u001b[1;32mc:\\Users\\crazy\\source\\repos\\CS474-Deep-Learning\\JupyterNotebook\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:397\u001b[0m, in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m input_shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(input_shape) \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`input_shape` must be a tuple of three integers.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         )\n\u001b[0;32m    400\u001b[0m     \u001b[39mif\u001b[39;00m input_shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m weights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    402\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe input must have 3 channels; Received \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`input_shape=\u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    404\u001b[0m         )\n",
            "\u001b[1;31mValueError\u001b[0m: `input_shape` must be a tuple of three integers."
          ]
        }
      ],
      "source": [
        "# expand dims for channels?\n",
        "\n",
        "#model = applications.resnet_v2.ResNet101V2(\n",
        "#    include_top=False,\n",
        "#    weights='imagenet',\n",
        "#    input_tensor=x_train,\n",
        "#    input_shape=x_train.shape,\n",
        "#    pooling=None,\n",
        "#    classes=1,\n",
        "#    classifier_activation='softmax'\n",
        "#)\n",
        "\n",
        "desiredLevels = 2\n",
        "\n",
        "def CreateConvLayer(convLayers, model, filters, kernel_size, activation = None, padding = \"valid\"):\n",
        "    conv = layers.Conv2D(\n",
        "        filters= filters, #num of filters for conv\n",
        "        kernel_size = kernel_size, \n",
        "        padding = padding,\n",
        "        activation = activation,\n",
        "        #input_shape = (28, 28, 1) #only 28 params \n",
        "    )\n",
        "    \n",
        "    convLayers.append(conv)\n",
        "    model.add(conv)\n",
        "    \n",
        "def CreateMaxPoolLayer(poolLayers, model, pool_size, strides):\n",
        "    pool = layers.MaxPooling2D(\n",
        "        pool_size = pool_size,\n",
        "        strides = strides,\n",
        "    )\n",
        "    \n",
        "    poolLayers.append(pool)\n",
        "    model.add(pool)\n",
        "    \n",
        "def CreateConvBlock(\n",
        "    model, convLayers, poolLayers, normLayers, activationLayers,\n",
        "    filters, kernel_size, activation,\n",
        "    pool_size, strides\n",
        "):\n",
        "    CreateConvLayer(convLayers, model, filters, kernel_size)\n",
        "    #CreateMaxPoolLayer(poolLayers, model, pool_size, strides)\n",
        "    \n",
        "    dropout = layers.Dropout(0.2)\n",
        "    model.add(dropout)\n",
        "    \n",
        "    norm = layers.BatchNormalization()\n",
        "    model.add(norm)\n",
        "    normLayers.append(norm)\n",
        "\n",
        "    activ = layers.Activation(activation)\n",
        "    model.add(activ)\n",
        "    activationLayers.append(activ)\n",
        "    \n",
        "# Create a fully conv NN\n",
        "model_fcn = keras.Sequential()\n",
        "\n",
        "convLayers = []\n",
        "poolLayers = []\n",
        "normLayers = []\n",
        "activationLayers = []\n",
        "\n",
        "# Input layer\n",
        "input = layers.Input(shape=(None, None, 1))\n",
        "model_fcn.add(input)\n",
        "\n",
        "CreateConvBlock(\n",
        "    model_fcn, convLayers, poolLayers, normLayers, activationLayers,\n",
        "    filters=8, kernel_size=3, activation='relu',\n",
        "    pool_size=2, strides=2\n",
        ")\n",
        "\n",
        "CreateConvBlock(\n",
        "    model_fcn, convLayers, poolLayers, normLayers, activationLayers,\n",
        "    filters=16, kernel_size=3, activation='softmax',\n",
        "    pool_size=2, strides=2\n",
        ")\n",
        "\n",
        "globMaxPool = layers.GlobalMaxPooling2D()\n",
        "model_fcn.add(globMaxPool)\n",
        "\n",
        "#model_fcn(inputs=x_train, outputs=y_train)\n",
        "\n",
        "#need normalization and output layers\n",
        "\n",
        "#specify optimization\n",
        "model_fcn.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_fcn.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5uxl6ePHj6G",
        "outputId": "4944fa13-c62c-4945-b6b5-d8e11eecf5de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_20 (InputLayer)       [(None, 231, 231, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 229, 229, 128)     1280      \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 229, 229, 128)     0         \n",
            "                                                                 \n",
            " batch_normalization_49 (Bat  (None, 229, 229, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 229, 229, 128)     0         \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 229, 229, 2)       258       \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 229, 229, 2)       0         \n",
            "                                                                 \n",
            " batch_normalization_50 (Bat  (None, 229, 229, 2)      8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_max_pooling2d_19 (Gl  (None, 2)                0         \n",
            " obalMaxPooling2D)                                               \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,058\n",
            "Trainable params: 1,798\n",
            "Non-trainable params: 260\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def construct_image_batch(image_group, BATCH_SIZE):\n",
        "    # get the max image shape\n",
        "    max_shape = tuple(max(image.shape[x] for image in image_group) for x in range(3))\n",
        "\n",
        "    # construct an image batch object\n",
        "    image_batch = np.zeros((BATCH_SIZE,) + max_shape, dtype='float32')\n",
        "\n",
        "    # copy all images to the upper left part of the image batch object\n",
        "    for image_index, image in enumerate(image_group):\n",
        "        image_batch[image_index, :image.shape[0], :image.shape[1], :image.shape[2]] = image\n",
        "\n",
        "    return image_batch\n",
        "\n",
        "classes = 2\n",
        "\n",
        "# Input layer\n",
        "input = layers.Input(shape=(231, 231, 1)) #test with smallest input shape to determine # of conv blocks?\n",
        "\n",
        "# input convolution block\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, strides=1)(input)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "\n",
        "# middle convolution block\n",
        "#x = layers.Conv2D(filters=64, kernel_size=3, strides=1)(x)\n",
        "#x = layers.Dropout(0.2)(x)\n",
        "#x = layers.BatchNormalization()(x)\n",
        "#x = layers.Activation('relu')(x)\n",
        "\n",
        "# middle convolution block\n",
        "#x = layers.Conv2D(filters=32, kernel_size=3, strides=1)(x)\n",
        "#x = layers.Dropout(0.2)(x)\n",
        "#x = layers.BatchNormalization()(x)\n",
        "#x = layers.Activation('relu')(x)\n",
        "\n",
        "# final convolution block\n",
        "x = layers.Conv2D(filters=classes, kernel_size=1, strides=1)(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.GlobalMaxPooling2D()(x)\n",
        "predictions = layers.Activation('relu')(x)\n",
        "\n",
        "model = keras.Model(inputs=input, outputs=predictions)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO5uAwL4Hj6G",
        "outputId": "83dc57e0-a9af-4ec2-989c-03009f8ee725"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#train model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model_fcn\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      3\u001b[0m     x_train, \u001b[39m#should be 2d inputs\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m     y_train, \u001b[39m#already onehot\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\crazy\\source\\repos\\CS474-Deep-Learning\\JupyterNotebook\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\crazy\\source\\repos\\CS474-Deep-Learning\\JupyterNotebook\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
            "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
          ]
        }
      ],
      "source": [
        "def train(model, train_generator, val_generator, epochs = 50):\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "    checkpoint_path = './snapshots'\n",
        "    os.makedirs(checkpoint_path, exist_ok=True)\n",
        "    model_path = os.path.join(checkpoint_path, 'model_epoch_{epoch:02d}_loss_{loss:.2f}_acc_{acc:.2f}_val_loss_{val_loss:.2f}_val_acc_{val_acc:.2f}.h5')\n",
        "    \n",
        "    history = model.fit_generator(generator=train_generator,\n",
        "            steps_per_epoch=len(train_generator),\n",
        "            epochs=epochs,\n",
        "            callbacks=[keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)],\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=len(val_generator)\n",
        "        )\n",
        "\n",
        "    return history\n",
        "\n",
        "#train model\n",
        "history = model_fcn.fit(\n",
        "    x_train, #should be 2d inputs\n",
        "    y_train, #already onehot\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_split=0.2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HdsbyQRHj6H"
      },
      "outputs": [],
      "source": [
        "#test accuracy\n",
        "y_test_pred = model_fcn.predict(x_test)\n",
        "y_test_pred = np.argmax(y_test_pred, axis=1) #still need to do bc pred is prob?\n",
        "test_err = np.sum(y_test == y_test_pred) / y_test.shape[0]\n",
        "\n",
        "print(f'test accuracy: {test_err * 100}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKaKEEa0Hj6H"
      },
      "outputs": [],
      "source": [
        "#history of training and validation accuracu\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training acc', 'validation acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2J8oG7QHj6H"
      },
      "outputs": [],
      "source": [
        "#get access to filters/kernels\n",
        "weights = convLayers[0].get_weights()[0][:, :, 0, :] #arr of a buncha nested lists, 0 bc only have 1 channel (28, 28, 1, 8)\n",
        "\n",
        "#can get access to other params this way \n",
        "\n",
        "for i in range(1, 8):\n",
        "    plt.subplot(2, 4, i)\n",
        "    plt.imshow(weights[:,:,i], cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "#how get access to feature maps?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('JupyterNotebook': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7e1b2f627b942c46ec4bf47ff4ea2a9cdb5031d2bd74349327a6cc0e56088180"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
